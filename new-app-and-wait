#!/usr/bin/python3

import sys
import argparse
import functools
import logging
import re
import socket
import subprocess
import tempfile
import time
import urllib3

from vshn_npo import constants
from vshn_npo import oc_client
from vshn_npo import retry
from vshn_npo import utils
from vshn_npo import iputils


def capture_curl(url, options=None, curl_binary=constants.DEFAULT_CURL_BINARY):
  cmd = [
    curl_binary,
    "--verbose",
    "--location",
    "--silent",
    "--show-error",
    "--fail",
    "--retry", "3",
    "--max-time", "300",
    ]

  if options:
    cmd.extend(options)

  cmd.append(url)

  logging.debug(cmd)
  return subprocess.check_output(cmd).decode("UTF-8")


def check_url_anyip(url, pattern, timeout):
  """Check :param:`url` using all IP addresses returned for host.

  Resolve the host for the given URL and attempt to retrieve the URL via all
  returned IP addresses (IPv4 and IPv6). All requests must succeed and contain
  the given pattern.

  :param url: URL string
  :param pattern: Compiled regular expression

  """
  logging.info("Checking access to \"%s\" via all load balancers", url)

  tcalc = utils.Timeout(timeout)

  parsed_url = urllib3.util.parse_url(url)

  if parsed_url.port:
    port = parsed_url.port
  else:
    port = urllib3.connection.port_by_scheme.get(parsed_url.scheme)

  if not port:
    raise Exception("Can't determine port for URL {!r}".format(url))

  checks = []

  logging.info("Resolving host \"%s\"", parsed_url.host)
  addrinfo = socket.getaddrinfo(parsed_url.host, port, type=socket.SOCK_STREAM)

  host_has_global_ip6 = iputils.host_has_global_ip6()

  for (af, socktype, proto, _, sa) in addrinfo:
    if af == socket.AF_INET6 and not host_has_global_ip6:
      # Skip check over IPv6 if the host running the check doesn't have any
      # global IPv6 addresses
      continue

    if af == socket.AF_INET:
      (ipaddr, _) = sa
    elif af == socket.AF_INET6:
      (ipaddr, _, _, _) = sa
    else:
      raise Exception("Unsupported address family: {!r}".format(af))

    opts = [
        "--resolve", "{}:{}:{}".format(parsed_url.host, port, ipaddr),
        "--max-time", "{}".format(int(max(10, min(300, tcalc.remaining)))),
        ]

    checks.append((ipaddr, url, opts))

  delay = utils.Delayer(1.0, 30.0)

  while checks:
    failed = []

    while checks:
      (ipaddr, url, opts) = checks.pop()

      logging.info("Retrieving %r from %r", url, ipaddr)

      try:
        text = capture_curl(url, options=opts)
      except subprocess.CalledProcessError as err:
        logging.error("Request error: %s", err)
        failed.append((ipaddr, url, opts))
      else:
        if not pattern.search(text):
          raise Exception("Expected pattern \"{}\" not found".format(pattern.pattern))

    checks.extend(failed)

    if tcalc.expired:
      raise Exception("Not available via all IP addresses after {:0.0f} seconds".
                      format(tcalc.elapsed))

    delay.sleep(tcalc.remaining)


class ExpectedPatternContext(retry.UrlWaitContext):
  def __init__(self, pattern):
    super(ExpectedPatternContext, self).__init__()

    self._pattern = pattern

  def check_response(self, resp):
    """Fail unless response contains pattern caller is looking for.

    """
    super(ExpectedPatternContext, self).check_response(resp)

    if not self._pattern.search(resp.text):
      raise Exception("Expected pattern \"{}\" not found".format(self._pattern.pattern))

    logging.info("Pattern found in response")


def Check(client, args, timeout):
  appname = "testapp"

  with tempfile.TemporaryDirectory() as tmpdir:
    create_cmd = [
      "new-app",
      "--name={}".format(appname),
      args.source,
      ]

    if args.strategy is not None:
      create_cmd.append("--strategy={}".format(args.strategy))

    logging.info("Creating application from %s", args.source)
    client.run(create_cmd, env_override={
      "TMPDIR": tmpdir,
      })

  client.run(["expose", "svc", appname])
  # This is required for some cases where a CDN is running in
  # front of the cluster and the CDN only makes HTTPS connections to the
  # backends. We always patch the route to be available over HTTP and HTTPS.
  client.run(["patch", "route", appname, "-p",
    '{"spec":{"tls":{"termination":"Edge","insecureEdgeTerminationPolicy":"Allow"}}}'])

  # Construct application URL
  route = client.capture_json(["get", "--output=json", "route", appname])
  host = route["spec"]["host"]

  utils.validate_fqdn(host)

  url = "http://{}{}".format(host, args.path)

  # Wait until application becomes available
  ctx = ExpectedPatternContext(args.pattern)

  logging.info("Waiting for %s to match pattern %r", url, args.pattern)

  return (url, retry.wait_for_url(url, timeout.remaining, ctx=ctx))


def get_names(client, kind):
  return client.capture_output([
    "get", "--no-headers", "--show-kind", "--output=name",
    "--ignore-not-found", kind,
    ]).splitlines()


def collect_logs_inner(client, kind, has_logs):
  names = sorted(get_names(client, kind))

  logging.debug("Objects of type %r: %r", kind, names)

  for i in names:
    client.run(["describe", "--show-events", i], ignore_errors=True)

    if has_logs:
      logging.debug("Logs for %r", i)
      client.run(["logs", "--timestamps", i], ignore_errors=True)


def collect_logs(client):
  client.run(["status", "-v"], ignore_errors=True)

  for kind in [
      "build",
      "deployment",
      "deploymentconfig",
      "replicationcontroller",
      "pod",
      ]:
    collect_logs_inner(client, kind, True)

  for kind in [
      "endpoints",
      "events",
      "imagestreamimages",
      "imagestreams",
      "imagestreamtags",
      "limitranges",
      "quota",
      "rolebindings",
      "routes",
      "secrets",
      "serviceaccounts",
      "services",
      ]:
    collect_logs_inner(client, kind, False)


def main():
  arg_formatter = argparse.ArgumentDefaultsHelpFormatter
  parser = argparse.ArgumentParser(formatter_class=arg_formatter)
  parser.add_argument("--nagios-output", type=str, metavar="FILE", default=None,
                      help=("Write Nagios-compatile output to FILE rather than"
                            " standard output"))
  parser.add_argument("--oc", type=str, default=constants.DEFAULT_OC_BINARY,
                      help="Path to OpenShift client binary")
  parser.add_argument("--strategy", choices=["docker", "source"], default=None,
                      help=("Specify the build strategy to use if"
                            " detection should not be used"))
  parser.add_argument("-w", "--warning", type=int, metavar="SEC", default=5 * 60,
                      help=("Warn if application takes more given number of"
                            " seconds to become available"))
  parser.add_argument("-c", "--critical", type=int, metavar="SEC", default=15 * 60,
                      help=("Fail if application takes more given number of"
                            " seconds to become available"))
  parser.add_argument("--project-prefix", type=str, default="e2e",
                      help="Prefix for project name")
  parser.add_argument("--path", type=str, default="/",
                      help="Resource to request from application")
  parser.add_argument("--pattern", type=re.compile, default="<body>",
                      help=("Regular expression pattern to expect in body;"
                            " use \"(?i)\" for a case-insensitive pattern"))
  parser.add_argument("--pattern-from", type=argparse.FileType("r"),
                      default=None, metavar="FILE",
                      help="Load expected pattern from file")
  parser.add_argument("--project-initial-wait", type=int, metavar="SEC", default=3,
                      help=("Wait for given number of seconds after creating"
                            " the project until starting the build"))
  parser.add_argument("config", type=str,
                      help="Configuration file with login credentials")
  parser.add_argument("source", type=str,
                      help=("Source code URL, template name or image name;"
                            " see \"oc new-app --help\""))
  args = parser.parse_args()

  if args.critical < args.warning:
    parser.error("--warning must be less than --critical")

  if args.pattern_from is not None:
    args.pattern = re.compile(args.pattern_from.read().rstrip())
    args.pattern_from = None

  logging.basicConfig(level=logging.NOTSET,
                      format="%(asctime)s %(message)s")

  with utils.NagiosOutputFile(args.nagios_output) as exit_fn, \
       oc_client.TemporaryConfig(args.config) as cfgfile:
    cl = oc_client.Client(args.oc, cfgfile)

    cl.run(["whoami"])
    cl.run(["version"])

    namer = oc_client.ProjectNamer(args.project_prefix)

    # Get rid of old projects
    oc_client.cleanup_projects(cl, namer, 2 * args.critical)

    timeout = utils.Timeout(max(args.warning, args.critical))

    project_name = oc_client.create_project(cl, namer)

    cl.namespace = project_name

    # Workaround for service account token generation is delayed
    # https://bugzilla.redhat.com/show_bug.cgi?id=1719792
    time.sleep(args.project_initial_wait)

    try:
      (url, duration) = Check(cl, args, timeout)

      check_url_anyip(url, args.pattern, timeout.remaining)
    finally:
      collect_logs(cl)

    logging.info("Deleting project \"%s\"", project_name)
    oc_client.delete_project(cl, project_name, ignore_errors=True)

    if duration >= args.warning:
      code = constants.STATE_WARNING
    else:
      code = constants.STATE_OK

    noneempty_fn = lambda value: "" if value is None else value

    # http://docs.icinga.org/latest/en/perfdata.html#perfdata-format
    metrics = [
        ("duration={}s;{};{};0".
         format(int(duration), noneempty_fn(args.warning),
                noneempty_fn(args.critical))),
        ]

    exit_fn(code,
            ("Available after {:0.0f} seconds at {}".
             format(duration, time.asctime())),
            metrics=metrics)


if __name__ == "__main__":
  main()

# vim: set sw=2 sts=2 et :
